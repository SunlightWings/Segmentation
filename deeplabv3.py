# -*- coding: utf-8 -*-
"""deeplabv3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZJa12Lp4EqHW484XQbeYVbHt4Fm81F9K
"""

from google.colab import drive
# Mount Google Drive
drive.mount('/content/drive')

import tensorflow as tf

import numpy as np
import os
import cv2
import torch
import torchvision.transforms as transforms
from google.colab.patches import cv2_imshow
from torchvision import models

# Load the DeepLabV3+ model
model2 = models.segmentation.deeplabv3_resnet50(pretrained=True)
model2.eval()

# Load the labels for DeepLabV3+ (21 classes)
LABELS = [
    (0, 0, 0),    # 0=Background
    (128, 0, 0),  # 1=Hat
    (255, 0, 0),  # 2=Hair
    (0, 85, 0),   # 3=Glove
    (170, 0, 51),  # 4=SunGlasses
    (255, 85, 0),  # 5=UpperClothes
    (0, 0, 85),     # 6=Dress
    (0, 119, 221),  # 7=Coat
    (85, 85, 0),    # 8=Socks
    (0, 85, 85),    # 9=Pants
    (85, 51, 0),    # 10=Jumpsuits
    (52, 86, 128),  # 11=Scarf
    (0, 128, 0),    # 12=Skirt
    (0, 0, 255),    # 13=Face
    (51, 170, 221),  # 14=LeftArm
    (0, 255, 255),   # 15=RightArm
    (85, 255, 170),  # 16=LeftLeg
    (170, 255, 85),  # 17=RightLeg
    (255, 255, 0),   # 18=LeftShoe
    (255, 170, 0),    # 19=RightShoe
    (170, 170, 50)   # 20=Skin/Neck/Chest (Newly added after running dataset_neck_skin_correction.py)
]

# Path to the folder containing the images
image_folder = "/content/drive/MyDrive/VITON/image/"

# List all the image files in the folder
image_files = os.listdir(image_folder)

# Process each image
for image_file in image_files:
    # Load the image
    image_path = os.path.join(image_folder, image_file)
    frame = cv2.imread(image_path)

    # Preprocess the image
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((192, 192)),
        transforms.ToTensor(),
        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
    ])
    input_image = transform(frame)
    input_image = input_image.unsqueeze(0)

    # Perform segmentation
    with torch.no_grad():
        output = model2(input_image)['out'][0]

    # Get the segmentation mask
    _, segmentation_mask = torch.max(output, 0)
    segmentation_mask = segmentation_mask.byte().cpu().numpy()

    # Create a blank mask for human regions (label 15 corresponds to human body)
    human_mask = segmentation_mask == 15

    # Resize mask to match the size of the input frame
    human_mask = cv2.resize(human_mask.astype(np.uint8), (frame.shape[1], frame.shape[0]))

    # Apply the mask to the original image to segment the human
    human_segmented = cv2.bitwise_and(frame, frame, mask=human_mask)

    # Display the segmented image
    cv2_imshow(human_segmented)
    cv2_imshow(human_segmented*255)    #The term "negative-like" is obtained here because the resulting image does not have negative pixel values but resembles the concept of a photographic negative, where the darker regions of the original image appear brighter and vice versa.
    cv2_imshow(human_mask*255)

    # Path to the output folder
    output_folder = "/content/drive/MyDrive/VITON/output_images/"
    os.makedirs(output_folder, exist_ok=True)


    # Save the images in the output folder
    cv2.imwrite(os.path.join(output_folder, f"{image_file}_human_segmented.png"), human_segmented)
    cv2.imwrite(os.path.join(output_folder, f"{image_file}_human_boundary.png"), human_segmented*255)
    cv2.imwrite(os.path.join(output_folder, f"{image_file}_human_mask.png"), human_mask*255)